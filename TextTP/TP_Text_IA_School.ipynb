{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TP - Text - IA School",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1ae2VW1fSNMSTPRWYXEi9RsCP-ddvYrqt",
      "authorship_tag": "ABX9TyOe/9sCe7jGFrkkf0bw9mMY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Whole-Brain/data-science-utils/blob/master/TextTP/TP_Text_IA_School.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FaKROSWjXdT5",
        "colab_type": "text"
      },
      "source": [
        "**MINING OF MASSIVE DATASETS : k-NEAREST NEIGHBOR, DECISION TREES**\n",
        "**IA SCHOOL**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kV56co7LHYJe",
        "colab_type": "text"
      },
      "source": [
        "# I - k-Nearest Neighbor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYzeXdFaQBpQ",
        "colab_type": "text"
      },
      "source": [
        "1. **Collecte de document**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzyo2wzJP0F3",
        "colab_type": "text"
      },
      "source": [
        "On commence par importer pandas afin de lire le fichier CSV. Cette étape n'est pas obligatoire si vous utilisez des listes de texte ou d'autre méthode pour lire des fichiers texte."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwREISBUNqJX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgIAkER7QF1f",
        "colab_type": "text"
      },
      "source": [
        "Grâce à cela, on peut lire directement notre fichier csv (pré-formaté par nos soins) via pandas qui nous le transforme en object DataFrame :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkR6UawmN9cI",
        "colab_type": "code",
        "outputId": "e8e4f4e6-a577-4287-8241-b5940cf4b5a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "my_path = \"drive/My Drive/Colab Notebooks/TP Text/\"\n",
        "df = pd.read_csv(my_path+\"apple_text.csv\", sep=\":::\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RbD3pbkQT1n",
        "colab_type": "text"
      },
      "source": [
        "Voici à quoi il ressemble : il n'y a que 19 observations, mais nous nous sommes assurés que toutes ont au minimum une fois le mot \"apple\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aj7MVMLvOCAv",
        "colab_type": "code",
        "outputId": "99980d45-c316-441c-9a4b-dd40d5a3e94e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        }
      },
      "source": [
        "df.head(20)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The apple is a deciduous tree, generally stand...</td>\n",
              "      <td>fruit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Commercially popular apple cultivars are soft ...</td>\n",
              "      <td>fruit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Commercially, apples can be stored for some mo...</td>\n",
              "      <td>fruit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Apples are obtained from medium-sized tree bel...</td>\n",
              "      <td>fruit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>One place where the ubiquitous apple does not ...</td>\n",
              "      <td>fruit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Pollination also depends on having blossom to ...</td>\n",
              "      <td>fruit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Temperatures at blossom time are also very sig...</td>\n",
              "      <td>fruit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Plants absorb arsenic from the soil in varying...</td>\n",
              "      <td>fruit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Apples are brimming with symbolic meanings and...</td>\n",
              "      <td>fruit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Apples play an important part in several Greek...</td>\n",
              "      <td>fruit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Apple software is powerful and intuitive. Our ...</td>\n",
              "      <td>product</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Apple Inc., formerly Apple Computer, Inc., Ame...</td>\n",
              "      <td>product</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Today after the bell, Apple reported the resul...</td>\n",
              "      <td>product</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Previously, Apple told investors that it expec...</td>\n",
              "      <td>product</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>The iMac epitomizes the sleek design and power...</td>\n",
              "      <td>product</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Steve Jobs (February 24, 1955-October 5, 2011)...</td>\n",
              "      <td>product</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Our Apple history feature includes information...</td>\n",
              "      <td>product</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>The two Steves - Jobs and Wozniak - may have b...</td>\n",
              "      <td>product</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>(You'd be surprised by how many people are con...</td>\n",
              "      <td>product</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 text     type\n",
              "0   The apple is a deciduous tree, generally stand...    fruit\n",
              "1   Commercially popular apple cultivars are soft ...    fruit\n",
              "2   Commercially, apples can be stored for some mo...    fruit\n",
              "3   Apples are obtained from medium-sized tree bel...    fruit\n",
              "4   One place where the ubiquitous apple does not ...    fruit\n",
              "5   Pollination also depends on having blossom to ...    fruit\n",
              "6   Temperatures at blossom time are also very sig...    fruit\n",
              "7   Plants absorb arsenic from the soil in varying...    fruit\n",
              "8   Apples are brimming with symbolic meanings and...    fruit\n",
              "9   Apples play an important part in several Greek...    fruit\n",
              "10  Apple software is powerful and intuitive. Our ...  product\n",
              "11  Apple Inc., formerly Apple Computer, Inc., Ame...  product\n",
              "12  Today after the bell, Apple reported the resul...  product\n",
              "13  Previously, Apple told investors that it expec...  product\n",
              "14  The iMac epitomizes the sleek design and power...  product\n",
              "15  Steve Jobs (February 24, 1955-October 5, 2011)...  product\n",
              "16  Our Apple history feature includes information...  product\n",
              "17  The two Steves - Jobs and Wozniak - may have b...  product\n",
              "18  (You'd be surprised by how many people are con...  product"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOjcuPaDQj_Z",
        "colab_type": "text"
      },
      "source": [
        "Il y a donc deux variables : la variable \"text\" qui contient des paragraphes de texte, et la variable \"type\" qui informe du type d'apple dont il est question : fruit ou product.\n",
        "On ne s'inquiète pas du fait que les observations sont regroupées par types."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zqtLZNRQ5_A",
        "colab_type": "text"
      },
      "source": [
        "2. **Séparation des échantillons**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ISGLy_VQ_vP",
        "colab_type": "text"
      },
      "source": [
        "Maintenant, on doit transformer nos données en quelque chose que notre futur algorithme pourra comprendre.\n",
        "Pour cela, on utilise un CountVectorizer, que nous devons importer avant tout."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLIStp3rOFlG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUzXCWd9ROcX",
        "colab_type": "text"
      },
      "source": [
        "Le CountVectorizer procède ainsi :\n",
        "1.   Si l'argument stop_words est renseigné, il va comprendre qu'il devra supprimer tous les mots \"inutiles\" et tous les caractères. \n",
        "En anglais, ce sera par exemple : in, for, a, the, if...\n",
        "2.   Lors du fit, il va compter tous les mots qui restent, par observation (par ligne). On peut imaginer que la grande majorité des mots auront 0 occurence sur toutes les lignes sauf une.\n",
        "3. Lors du transform, il renvoie le texte sous forme de vecteur (liste). C'est à ce point-là que le lien entre l'index du mot et le mot est perdu, seul count_vect le connait. Pour ceux que ça intéresse, il s'agit de l'attribut vocabulary_ (https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEF7JjLuON1v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "count_vect = CountVectorizer(stop_words=\"english\")\n",
        "vectorized_data = count_vect.fit_transform(df.text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYNIHMxLTIsg",
        "colab_type": "text"
      },
      "source": [
        "Nos datas sont presque prêtes, il nous reste encore à les séparer en deux échantillons : 2/3 train et 1/3 test.\n",
        "Cette procédure est à connaître absolument.\n",
        "Tout d'abord, il faut import la fonction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvwABfnbPYW2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmZwwJkzTaNH",
        "colab_type": "text"
      },
      "source": [
        "La fonction train_test_split fonctionne ainsi.\n",
        "Elle a besoin de 2 arguments minimum :\n",
        "1. La data (sans les réponses)\n",
        "2. Les réponses\n",
        "3. La portion de l'ensemble que nous gardons comme test (par défaut si non renseigné : 0.25)\n",
        "\n",
        "Le but est de pouvoir entraîner notre modèle par la suite avec l'échantillon train, puis le tester avec des données qu'il n'a jamais vu : l'échantillon test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nb2LKLNqOm14",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(vectorized_data, df.type, test_size = 1/3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6b8Rs6pT9C5",
        "colab_type": "text"
      },
      "source": [
        "Etant donné que l'algorithme que nous allons utiliser a besoin d'arrays (et pas de vecteurs), il faut les convertir :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDr0JYYDPOdm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.toarray()\n",
        "X_test = X_test.toarray()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDhe-1tVWm7R",
        "colab_type": "text"
      },
      "source": [
        "3. **Le Machine Learning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xY-ozYbZUKV0",
        "colab_type": "text"
      },
      "source": [
        "Maintenant on importe l'algorithme en question : KNeighborsClassifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYEGh_JDPbn_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1Oj23SnUPPJ",
        "colab_type": "text"
      },
      "source": [
        "On l'instancie. Le paramètre que j'ai choisi de modifier ici est n_neighbors. Rien ne vous empêche d'essayer tous les paramètres que vous voulez. Comme d'hab, il faut lire la doc qui est très complète et lisible : https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n",
        "Puis on l'entraîne (fit) avec les données d'entrainement.\n",
        "Fit est une méthode récurrente dans tous les algos de ML, elle a toujours besoin de deux arguments : la donnée et les réponses (avec len(donnée) = len(réponses) !)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgehpidMOTLH",
        "colab_type": "code",
        "outputId": "67a8b410-38bd-4164-8eaf-ae4585eb826d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "neigh = KNeighborsClassifier(n_neighbors = 6)\n",
        "neigh.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
              "                     metric_params=None, n_jobs=None, n_neighbors=6, p=2,\n",
              "                     weights='uniform')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIc9soinU344",
        "colab_type": "text"
      },
      "source": [
        "Comme on peut le voir, nos observations (rappel : séparées par mot puis transformées en nombre d'occurence) ont bien la même longueur.\n",
        "Et comme on a mis test_size = 1/3, on a bien 1/3 de test et 2/3 de train.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJc6mhNKOjmP",
        "colab_type": "code",
        "outputId": "29c7facc-db4f-447a-cc88-3890206ce40b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(\"X_train shape = \", X_train.shape)\n",
        "print(\"X_text shape = \", X_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train shape =  (12, 521)\n",
            "X_text shape =  (7, 521)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kwu4vHsgW4XY",
        "colab_type": "text"
      },
      "source": [
        "4. **Prédiction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipUpVIHdVYro",
        "colab_type": "text"
      },
      "source": [
        "Maintenant, on peut demander à notre algo de prédire les réponses pour nos données de test. On les stock dans une variable, pour plus tard faire des études dessus (ex: plusieurs fonctions d'erreurs, ou par curiosité pour savoir quelles réponses il a donné à quoi, avec un peu de bidouillage)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMIcNZYMOcuQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = neigh.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VStVnkEeVvCa",
        "colab_type": "text"
      },
      "source": [
        "Mais si on veut juste connaître sa précision, on appelle juste la méthode score (qui prend la donnée et ses réponses en arguments).\n",
        "Ici : je l'ai fait deux fois : une fois sur les échantillons train, et une fois sur l'échantillon test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yoyz22jwPA2P",
        "colab_type": "code",
        "outputId": "e6d23790-1d1e-4eff-aaa0-090d53505be9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(\"Score sur le train : \", neigh.score(X_train, y_train))\n",
        "print(\"Score sur le test : \", neigh.score(X_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score sur le train :  0.75\n",
            "Score sur le test :  0.2857142857142857\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLSS3TxZWA0h",
        "colab_type": "text"
      },
      "source": [
        "(C'est très nul !)\n",
        "\n",
        "Pourquoi faire des scores sur les train aussi ? Pour une raison :\n",
        "si le score train est très supérieur au score test, ça s'appelle de l'\"overfitting\" ; ça veut dire que votre algo connait trop bien ses données d'entrainement et ne sera pas assez souple pour précisément deviner des données qu'il ne connaît pas déjà (l'échantillon test).\n",
        "Ca peut-être utile quand on connait bien l'algo car ça indique dans quel sens tweeker ses paramètres."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbIAiqtMWx7B",
        "colab_type": "text"
      },
      "source": [
        "5. **La suite ?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_G5NqPMOWz-J",
        "colab_type": "text"
      },
      "source": [
        "1. Tester les autres algos dans le PDF de la prof.\n",
        "2. Comprendre l'autre méthode de séparation des échantillons : CrossValidation\n",
        "3. (Avancée) Essayer de trouver les paramètres optimaux grâce au GridSearchCV qui permet de tester toutes les combinaisons de paramètres grâce aux valeurs qu'on lui renseigne sous cette forme : "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsZbZrQbo6J1",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "gdcv = GridSearchCV(estimator = neigh, param_grid= { \"n_neighbors\" : (2, 3, 5,10), \"algorithm\" : (\"auto\",\"ball_tree\",\"kd_tree\"), \"leaf_size\": (5, 15, 30 , 50) } ) \n",
        "# voir les différents paramètres qu'on peut tuner sur le site de sklearn et la page de votre algo\n",
        "# ici : https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n",
        "gdcv.fit(...etc...)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9YDneI2HIK-",
        "colab_type": "text"
      },
      "source": [
        "# II - Arbre décisionnel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96PsF2ZiHLCE",
        "colab_type": "text"
      },
      "source": [
        "### Premier essai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDy8zidGCeuK",
        "colab_type": "text"
      },
      "source": [
        "Afin de lire les données fournies, nous nécessitons numpy que nous importons."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcee7bWDHWb5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-S9tBLG6DDic",
        "colab_type": "text"
      },
      "source": [
        "Nos données sont déjà séparées en 4 : les données d'entrées pour l'entrainement et le test, et les labels (les réponses attendues) pour l'entrainement et le test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXgrmwjvLoge",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tree_data_path = my_path+\"TextTP/DecisionTreeData/\"\n",
        "training_data = np.load(tree_data_path+'training_data.npy')\n",
        "training_class = np.load(tree_data_path+'training_class.npy')\n",
        "test_data = np.load(tree_data_path+'test_data.npy')\n",
        "test_class = np.load(tree_data_path+'test_class.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIPuF5UrDRKc",
        "colab_type": "text"
      },
      "source": [
        "Nous utiliserons un autre type d'algorithme que SciKitLearn implémente également : les arbres décisionnels. Nous importons donc le modèle que nous allons utiliser et qui se trouve dans le module tree : le DecisionTreeClassifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntuNvBntL-vu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYDY9VShD1zD",
        "colab_type": "text"
      },
      "source": [
        "Nous instancions un arbre, avec les paramètres demandés dans l'exercice.\n",
        "Puis nous entraînons cet arbre avec nos échantillons d'entrainement.\n",
        "Comme d'habitude, on utilise la méthode \"fit\" qui prend deux arguments : les données d'entrée et les réponses."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSsNitg5K45n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf = DecisionTreeClassifier(criterion='gini', random_state=np.random.RandomState(130))\n",
        "clf = clf.fit(training_data, training_class)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHKTVJADEOWa",
        "colab_type": "text"
      },
      "source": [
        "Maintenant que notre arbre est entraîné, nous pouvons lui demander des prévision sur des données qu'il ne connait pas : l'échantillons test. Nous gardons ses réponses dans une variable que nous appelons \"test_pred\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXDzMYpMK6N6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_pred = clf.predict(test_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70ZBV2xRElab",
        "colab_type": "text"
      },
      "source": [
        "Comme expliqué dans la Partie 1, nous allons également demander les prédictions de notre arbre sur les données d'entraînement afin de savoir si notre modèle \"overfit\".\n",
        "Cette procédure est d'autant plus importante que, du fait de leur principe de fonctionnement, l'overfitting est très courant avec les arbres décisionnels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9GME7b7EbXz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_pred = clf.predict(training_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7jmE_O5FFAr",
        "colab_type": "text"
      },
      "source": [
        "Afin de connaître les scores de notre arbre, il nous faut un autre type de calcul que nous pouvons importer du module metrics de SciKitLearn : accuracy_score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zi6oaZFsN7b3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EXU3ULjFRUr",
        "colab_type": "text"
      },
      "source": [
        "Voyons les scores de notre arbre sur les réponses précédemment récupérées."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOIG9X_POXeu",
        "colab_type": "code",
        "outputId": "58e8968c-1f8e-4e9c-a1f0-30a8b2c0897f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(\"Accuracy on train =\", accuracy_score(training_class, train_pred))\n",
        "print(\"Accuracy on test = \", accuracy_score(test_class, test_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on train = 1.0\n",
            "Accuracy on test =  0.54\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVj--BBTFZDU",
        "colab_type": "text"
      },
      "source": [
        "Nous remarquons une mauvaise précision sur l'échantillon de test alors que la précision est maximale sur l'échantillon d'entraînement ; il s'agit d'un cas évident d'overtfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2w-LDpfFpOk",
        "colab_type": "text"
      },
      "source": [
        "Plutôt que de générer un fichier PDF, nous pouvons afficher directement notre arbre sur le présent notebook, grâce au module graphviz, que nous importons."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHX7VKwG0FBC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.tree import export_graphviz\n",
        "import graphviz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwL4tb_G3NrR",
        "colab_type": "code",
        "outputId": "ea02603d-5a4d-444b-df15-8bf7ab84de39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 518
        }
      },
      "source": [
        "display(graphviz.Source(export_graphviz(clf)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<graphviz.files.Source at 0x7ff696465710>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: Tree Pages: 1 -->\n<svg width=\"510pt\" height=\"373pt\"\n viewBox=\"0.00 0.00 510.00 373.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 369)\">\n<title>Tree</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-369 506,-369 506,4 -4,4\"/>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"247.5,-365 122.5,-365 122.5,-297 247.5,-297 247.5,-365\"/>\n<text text-anchor=\"middle\" x=\"185\" y=\"-349.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">X[3] &lt;= 0.8</text>\n<text text-anchor=\"middle\" x=\"185\" y=\"-334.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.553</text>\n<text text-anchor=\"middle\" x=\"185\" y=\"-319.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 50</text>\n<text text-anchor=\"middle\" x=\"185\" y=\"-304.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [25, 22, 3]</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\">\n<title>1</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"176.5,-253.5 59.5,-253.5 59.5,-200.5 176.5,-200.5 176.5,-253.5\"/>\n<text text-anchor=\"middle\" x=\"118\" y=\"-238.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.0</text>\n<text text-anchor=\"middle\" x=\"118\" y=\"-223.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 25</text>\n<text text-anchor=\"middle\" x=\"118\" y=\"-208.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [25, 0, 0]</text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M163.0617,-296.9465C155.8946,-285.8215 147.9227,-273.4473 140.7007,-262.237\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"143.4574,-260.0532 135.0993,-253.5422 137.5728,-263.8442 143.4574,-260.0532\"/>\n<text text-anchor=\"middle\" x=\"129.8123\" y=\"-274.2767\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">True</text>\n</g>\n<!-- 2 -->\n<g id=\"node3\" class=\"node\">\n<title>2</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"311.5,-261 194.5,-261 194.5,-193 311.5,-193 311.5,-261\"/>\n<text text-anchor=\"middle\" x=\"253\" y=\"-245.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">X[3] &lt;= 1.65</text>\n<text text-anchor=\"middle\" x=\"253\" y=\"-230.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.211</text>\n<text text-anchor=\"middle\" x=\"253\" y=\"-215.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 25</text>\n<text text-anchor=\"middle\" x=\"253\" y=\"-200.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 22, 3]</text>\n</g>\n<!-- 0&#45;&gt;2 -->\n<g id=\"edge2\" class=\"edge\">\n<title>0&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M207.2657,-296.9465C212.9602,-288.2373 219.1552,-278.7626 225.0938,-269.6801\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"228.1411,-271.4151 230.6842,-261.13 222.2823,-267.5843 228.1411,-271.4151\"/>\n<text text-anchor=\"middle\" x=\"235.8058\" y=\"-281.8998\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">False</text>\n</g>\n<!-- 3 -->\n<g id=\"node4\" class=\"node\">\n<title>3</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"245.5,-157 128.5,-157 128.5,-89 245.5,-89 245.5,-157\"/>\n<text text-anchor=\"middle\" x=\"187\" y=\"-141.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">X[1] &lt;= 2.3</text>\n<text text-anchor=\"middle\" x=\"187\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.087</text>\n<text text-anchor=\"middle\" x=\"187\" y=\"-111.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 22</text>\n<text text-anchor=\"middle\" x=\"187\" y=\"-96.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 21, 1]</text>\n</g>\n<!-- 2&#45;&gt;3 -->\n<g id=\"edge3\" class=\"edge\">\n<title>2&#45;&gt;3</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M231.3891,-192.9465C225.8622,-184.2373 219.8494,-174.7626 214.0854,-165.6801\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"216.9729,-163.6979 208.6594,-157.13 211.0626,-167.4487 216.9729,-163.6979\"/>\n</g>\n<!-- 6 -->\n<g id=\"node7\" class=\"node\">\n<title>6</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"374,-157 264,-157 264,-89 374,-89 374,-157\"/>\n<text text-anchor=\"middle\" x=\"319\" y=\"-141.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">X[1] &lt;= 2.75</text>\n<text text-anchor=\"middle\" x=\"319\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.444</text>\n<text text-anchor=\"middle\" x=\"319\" y=\"-111.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 3</text>\n<text text-anchor=\"middle\" x=\"319\" y=\"-96.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 1, 2]</text>\n</g>\n<!-- 2&#45;&gt;6 -->\n<g id=\"edge6\" class=\"edge\">\n<title>2&#45;&gt;6</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M274.6109,-192.9465C280.1378,-184.2373 286.1506,-174.7626 291.9146,-165.6801\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"294.9374,-167.4487 297.3406,-157.13 289.0271,-163.6979 294.9374,-167.4487\"/>\n</g>\n<!-- 4 -->\n<g id=\"node5\" class=\"node\">\n<title>4</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"110,-53 0,-53 0,0 110,0 110,-53\"/>\n<text text-anchor=\"middle\" x=\"55\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.0</text>\n<text text-anchor=\"middle\" x=\"55\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 1</text>\n<text text-anchor=\"middle\" x=\"55\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 0, 1]</text>\n</g>\n<!-- 3&#45;&gt;4 -->\n<g id=\"edge4\" class=\"edge\">\n<title>3&#45;&gt;4</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M140.4617,-88.9777C127.3099,-79.3629 113.0257,-68.9203 99.968,-59.3743\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"101.727,-56.3247 91.5886,-53.2485 97.5958,-61.9757 101.727,-56.3247\"/>\n</g>\n<!-- 5 -->\n<g id=\"node6\" class=\"node\">\n<title>5</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"245.5,-53 128.5,-53 128.5,0 245.5,0 245.5,-53\"/>\n<text text-anchor=\"middle\" x=\"187\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.0</text>\n<text text-anchor=\"middle\" x=\"187\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 21</text>\n<text text-anchor=\"middle\" x=\"187\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 21, 0]</text>\n</g>\n<!-- 3&#45;&gt;5 -->\n<g id=\"edge5\" class=\"edge\">\n<title>3&#45;&gt;5</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M187,-88.9777C187,-80.7364 187,-71.887 187,-63.5153\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"190.5001,-63.2484 187,-53.2485 183.5001,-63.2485 190.5001,-63.2484\"/>\n</g>\n<!-- 7 -->\n<g id=\"node8\" class=\"node\">\n<title>7</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"374,-53 264,-53 264,0 374,0 374,-53\"/>\n<text text-anchor=\"middle\" x=\"319\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.0</text>\n<text text-anchor=\"middle\" x=\"319\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 2</text>\n<text text-anchor=\"middle\" x=\"319\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 0, 2]</text>\n</g>\n<!-- 6&#45;&gt;7 -->\n<g id=\"edge7\" class=\"edge\">\n<title>6&#45;&gt;7</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M319,-88.9777C319,-80.7364 319,-71.887 319,-63.5153\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"322.5001,-63.2484 319,-53.2485 315.5001,-63.2485 322.5001,-63.2484\"/>\n</g>\n<!-- 8 -->\n<g id=\"node9\" class=\"node\">\n<title>8</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"502,-53 392,-53 392,0 502,0 502,-53\"/>\n<text text-anchor=\"middle\" x=\"447\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.0</text>\n<text text-anchor=\"middle\" x=\"447\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 1</text>\n<text text-anchor=\"middle\" x=\"447\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 1, 0]</text>\n</g>\n<!-- 6&#45;&gt;8 -->\n<g id=\"edge8\" class=\"edge\">\n<title>6&#45;&gt;8</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M364.128,-88.9777C376.8813,-79.3629 390.7327,-68.9203 403.3947,-59.3743\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"405.6421,-62.0632 411.5202,-53.2485 401.4281,-56.4737 405.6421,-62.0632\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLdx1m45F2as",
        "colab_type": "text"
      },
      "source": [
        "Nous voyons des informations intéressantes : chaque cadre est une \"branche\" de notre arbre. Chaque branche correspond à une question binaire (en True ou False). \n",
        "ex : X[1] <= 165.\n",
        "\n",
        "Nous voyons également combien d'observations donnent chaque réponse, et leur future répartition dans les branches filles. ex: \"samples = 25\" indique qu'il y a 25 observations questionnées. Puis \"value = [0, 22, 3]\" indique que parmi ces 25 observations, aucune ne finira dans la catégorie 1, 22 finiront dans la catégorie 2 et 3 dans la catégorie 3.\n",
        "\n",
        "Les cadres qui n'ont pas d'enfants sont des feuilles et donnent donc la classification pour un certain nombre d'observations de nos données. L'arbre arrête donc de poser des questions lorsque toutes les observations de chaque feuille sont classées dans la même catégorie."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyvBsdb9HROi",
        "colab_type": "text"
      },
      "source": [
        "### Optimisation de l'arbre"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtDmRWHAHV8L",
        "colab_type": "text"
      },
      "source": [
        "Une méthode incoutournable en Machine Learning est le GridSearchCV (GSCV). C'est une autre chose à maitrîser.\n",
        "\n",
        "Le GridSearchCv consiste à essayer toutes les combinaisons de paramètres que nous lui fournissons, sur un modèle que nous lui fournissons également : il s'agira de notre arbre DecisionTreeClassifier.\n",
        "\n",
        "Après avoir essayer toutes les combinaisons, le GridSearchCV nous informera de la meilleure combinaison de paramètres, c'est-à-dire celle qui démontre le plus grand score de précision sur nos échantillons.\n",
        "\n",
        "Commençons par l'importer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wLKNaGc5FEN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Acy3JF0HuXj",
        "colab_type": "text"
      },
      "source": [
        "Avant de l'instancier, nous devons réfléchir à quels paramètres de notre arbre nous souhaitons \"tuner\".\n",
        "\n",
        "Pour cela, il est utile de faire des recherches spécifiques pour chaque modèle. Voici un exemple de source intéressante : https://medium.com/@mohtedibf/indepth-parameter-tuning-for-decision-tree-6753118a03c3\n",
        "\n",
        "Nous y trouvons l'ensemble des paramètres de notre arbre qu'il est intéressant de tuner, et une idée de l'échelle pour chacun d'eux. Nous y ajouterons le paramètres \"splitter\".\n",
        "\n",
        "Pour rappel, tous les paramètres sont décrits dans la documentation officielle (incoutournable !) : https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDPFFUKaJK2W",
        "colab_type": "text"
      },
      "source": [
        "GridSearchCV fonctionne grâce à un dictionnaire avec :\n",
        "- les paramètres en tant que clé.\n",
        "- les valeurs de chaque clé est une liste contenant toutes les valeurs que l'on souhaite tester."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tagqCt0X5QgK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "params= {\"max_features\":np.arange(2,training_data.shape[1]+1),\n",
        "         \"splitter\":[\"best\",\"random\"], \n",
        "         \"min_samples_split\":np.arange(2,20), \n",
        "         \"max_depth\":[None]+list(np.arange(2,16)),\n",
        "         \"min_samples_leaf\":np.arange(1,20)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRrVKhPrJax7",
        "colab_type": "text"
      },
      "source": [
        "Plusieurs remarques importantes ici.\n",
        "\n",
        "1.   Numpy met à disposition des fonctions permettant d'obtenir des listes simplement. linspace(i, j, n) donnera une liste de n valeurs espacée de manière régulières, de i à j. logspace fonctionne de manière similaire mais les valeurs et l'espacement se situeront sur une échelle logarithmique. (voir cellule ci-dessous pour des aperçus de ces deux fonctions) \n",
        "2.   Il est important de consulter la documentation et de s'assurer de renseigner le bon type de valeurs pour chaque paramètre, qui peuvent être numériques ou catégorielles (sous forme de string ou None).\n",
        "3. Le nombre total de combinaisons est facile à calculer : c'est le produit de nombre de chaque liste donnée ! On comprend donc que le temps nécessaire à GSCV augmente de manière exponentielle avec le nombre de paramètres et de valeurs renseignés.\n",
        "4. La méthode de séparation de GridSearchCV n'est pas basé sur un simple test_train_split. Il s'agit ici de cross-validation (par défaut : 5 folds). Nous devrons donc multiplier par 5 pour avoir une idée du nombre totale d'itérations sur notre arbre."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnFby8SyKoW2",
        "colab_type": "code",
        "outputId": "02919211-5e71-4248-d52e-9d37face741a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(\"Aperçu : linspace(1,10,10) = \", np.linspace(1,10,10))\n",
        "print(\"Aperçu : logspace(1,10,10) = \", np.logspace(1,10,10))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Aperçu : linspace(1,10,10) =  [ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10.]\n",
            "Aperçu : logspace(1,10,10) =  [1.e+01 1.e+02 1.e+03 1.e+04 1.e+05 1.e+06 1.e+07 1.e+08 1.e+09 1.e+10]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohcrWkPOLe0N",
        "colab_type": "text"
      },
      "source": [
        "Maintenant que notre dictionnaire de paramètres est prêt, nous instancions GridSearchCV en lui fournissant notre modèle et le dictionnaire de paramètres.\n",
        "\n",
        "Le paramètre n_jobs permettra, dans un environnement propice (les serveurs gratuits de Colab n'en est pas un) de prendre avantage des processeurs multi-coeurs. -1 signifie qu'il utilisera le maximum de coeurs disponibles (en  simplifié). Cela peut être un gain de temps important, de plusieurs ordres, si vous exécutez le code sur votre propre système.\n",
        "\n",
        "Le paramètre verbose à la valeur 1 permet de voir la progression du GridSearchCV dans la console."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DweiCl1k6Nk6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gscv = GridSearchCV(DecisionTreeClassifier(), param_grid=params,n_jobs=-1, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbEHiXPVMYX9",
        "colab_type": "text"
      },
      "source": [
        "Comme avec un modèle classique, nous appelons la méthode \"fit\" de notre instance de GridSearchCV, et nous lui fournissons les données d'entrée et réponses d'entraînement.\n",
        "\n",
        "Il faudra environ deux minutes pour tester toutes les combinaisons créées dans notre cadre actuel."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCnNly906ZOT",
        "colab_type": "code",
        "outputId": "dbfd5b14-418c-4540-f21e-c82f258a4880",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        }
      },
      "source": [
        "gscv.fit(training_data, training_class)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 30780 candidates, totalling 153900 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
            "  % (min_groups, self.n_splits)), UserWarning)\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 1288 tasks      | elapsed:    2.5s\n",
            "[Parallel(n_jobs=-1)]: Done 20488 tasks      | elapsed:   19.5s\n",
            "[Parallel(n_jobs=-1)]: Done 52488 tasks      | elapsed:   47.9s\n",
            "[Parallel(n_jobs=-1)]: Done 97288 tasks      | elapsed:  1.5min\n",
            "[Parallel(n_jobs=-1)]: Done 153745 tasks      | elapsed:  2.3min\n",
            "[Parallel(n_jobs=-1)]: Done 153900 out of 153900 | elapsed:  2.3min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=None, error_score=nan,\n",
              "             estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,\n",
              "                                              criterion='gini', max_depth=None,\n",
              "                                              max_features=None,\n",
              "                                              max_leaf_nodes=None,\n",
              "                                              min_impurity_decrease=0.0,\n",
              "                                              min_impurity_split=None,\n",
              "                                              min_samples_leaf=1,\n",
              "                                              min_samples_split=2,\n",
              "                                              min_weight_fraction_leaf=0.0,\n",
              "                                              presort='deprecated',\n",
              "                                              random_state=None,\n",
              "                                              splitter='best'),\n",
              "             iid=...\n",
              "             param_grid={'max_depth': [None, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
              "                                       13, 14, 15],\n",
              "                         'max_features': array([2, 3, 4]),\n",
              "                         'min_samples_leaf': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
              "       18, 19]),\n",
              "                         'min_samples_split': array([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
              "       19]),\n",
              "                         'splitter': ['best', 'random']},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwnf0FMhMikd",
        "colab_type": "text"
      },
      "source": [
        "Désormais, nous pouvons récupérer la liste des paramètres optimaux : l'attribut best_params_."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0Bo7TEq65Q9",
        "colab_type": "code",
        "outputId": "8b54bf1a-d3c2-4165-b462-c96831de5e53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(gscv.best_params_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'max_depth': 3, 'max_features': 3, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'random'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7f72OMz3NCcE",
        "colab_type": "text"
      },
      "source": [
        "GridSearchCV est pratique car il garde toutes les informations en mémoire. Nous pouvons voir le résultat pour chaque combinaison grâce à son attribut cv_results_. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6roAVTKjN1W1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# gscv.cv_results_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wx_U03D5Nzu_",
        "colab_type": "text"
      },
      "source": [
        "De plus, il utilisera cette combinaison optimale de paramètres lors des prédictions ultérieures. Nous n'avons donc pas de nécessité d'entraîner un autre arbre avec ces paramètres et nous pouvons calculer les scores directement grâce à la méthode predict de GridSearchCV.\n",
        "\n",
        "Comme d'habitude, nous calculons les scores sur les échantillons train et test pour identifier un possible overfitting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoTe8mBXNZ8d",
        "colab_type": "code",
        "outputId": "361608d7-f1f9-4b19-82c9-8f9577b5f746",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "gcv_train_pred = gscv.predict(training_data)\n",
        "gcv_test_pred = gscv.predict(test_data)\n",
        "print(\"Accuracy on train = \", accuracy_score(training_class, gcv_train_pred))\n",
        "print(\"Accuracy on test = \", accuracy_score(test_class, gcv_test_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on train =  0.92\n",
            "Accuracy on test =  0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmoApNxpc6B7",
        "colab_type": "text"
      },
      "source": [
        "Nous avons ici un problème : notre modèle overfit parfois et GridSearchCv identifiera dans ce cas une combinaison de paramètres amenant à un modèle incapable de prédire la réponse sur de nouvelles données. Nous voyons ici les limites de GridSearchCV. \n",
        "\n",
        "Nous allons donc adopter une stratégie semblable de combinaison de paramètre mais de manière programmatique. Nous pourrons donc ainsi sélectionner les meilleurs paramètres en fonction des résultats obtenus sur les prédiction de test, et non sur ceux de l'ensemble des échantillons d'entrainement.\n",
        "\n",
        "ParameterGrid est une classe utile afin de récupérer directement l'ensemble des combinaisons à partir de notre dictionnaire originale."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HX0LxkBRzPFR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import ParameterGrid"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6mQzl_cdGyR",
        "colab_type": "code",
        "outputId": "fc8c31aa-164d-429c-b954-069f21a1652a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "param_grid = ParameterGrid(params)\n",
        "\n",
        "result_list=[]\n",
        "best_param_index = -1\n",
        "best_score = 0\n",
        "# On teste et sauvegarde les résultats train et test de chaque combinaison.\n",
        "for i,param in enumerate(param_grid):\n",
        "    if i%int(2*len(param_grid)**0.5) == 0:\n",
        "        print(\"Testing parameters\",i,\"/\",len(param_grid),\" : \", param)\n",
        "    clf = DecisionTreeClassifier(criterion='gini',random_state=np.random.RandomState(130),**param)\n",
        "    clf=clf.fit(training_data, training_class)\n",
        "    clf_train_pred = clf.predict(training_data)\n",
        "    clf_test_pred = clf.predict(test_data)\n",
        "    results = [accuracy_score(training_class, clf_train_pred),\n",
        "               accuracy_score(test_class, clf_test_pred)]\n",
        "    result_list.append(results)\n",
        "    if results[1] > best_score:\n",
        "        best_score=results[1]\n",
        "        best_param_index = i\n",
        "\n",
        "print(\"\\nLes meilleurs paramètres sont : \\n\\t\",param_grid[best_param_index])\n",
        "print(\"Accuracy on train = \", result_list[best_param_index][0])\n",
        "print(\"Accuracy on test = \", best_score)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing parameters 0 / 30780  :  {'max_depth': None, 'max_features': 2, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}\n",
            "Testing parameters 350 / 30780  :  {'max_depth': None, 'max_features': 2, 'min_samples_leaf': 10, 'min_samples_split': 15, 'splitter': 'best'}\n",
            "Testing parameters 700 / 30780  :  {'max_depth': None, 'max_features': 3, 'min_samples_leaf': 1, 'min_samples_split': 10, 'splitter': 'best'}\n",
            "Testing parameters 1050 / 30780  :  {'max_depth': None, 'max_features': 3, 'min_samples_leaf': 11, 'min_samples_split': 5, 'splitter': 'best'}\n",
            "Testing parameters 1400 / 30780  :  {'max_depth': None, 'max_features': 4, 'min_samples_leaf': 1, 'min_samples_split': 18, 'splitter': 'best'}\n",
            "Testing parameters 1750 / 30780  :  {'max_depth': None, 'max_features': 4, 'min_samples_leaf': 11, 'min_samples_split': 13, 'splitter': 'best'}\n",
            "Testing parameters 2100 / 30780  :  {'max_depth': 2, 'max_features': 2, 'min_samples_leaf': 2, 'min_samples_split': 8, 'splitter': 'best'}\n",
            "Testing parameters 2450 / 30780  :  {'max_depth': 2, 'max_features': 2, 'min_samples_leaf': 12, 'min_samples_split': 3, 'splitter': 'best'}\n",
            "Testing parameters 2800 / 30780  :  {'max_depth': 2, 'max_features': 3, 'min_samples_leaf': 2, 'min_samples_split': 16, 'splitter': 'best'}\n",
            "Testing parameters 3150 / 30780  :  {'max_depth': 2, 'max_features': 3, 'min_samples_leaf': 12, 'min_samples_split': 11, 'splitter': 'best'}\n",
            "Testing parameters 3500 / 30780  :  {'max_depth': 2, 'max_features': 4, 'min_samples_leaf': 3, 'min_samples_split': 6, 'splitter': 'best'}\n",
            "Testing parameters 3850 / 30780  :  {'max_depth': 2, 'max_features': 4, 'min_samples_leaf': 12, 'min_samples_split': 19, 'splitter': 'best'}\n",
            "Testing parameters 4200 / 30780  :  {'max_depth': 3, 'max_features': 2, 'min_samples_leaf': 3, 'min_samples_split': 14, 'splitter': 'best'}\n",
            "Testing parameters 4550 / 30780  :  {'max_depth': 3, 'max_features': 2, 'min_samples_leaf': 13, 'min_samples_split': 9, 'splitter': 'best'}\n",
            "Testing parameters 4900 / 30780  :  {'max_depth': 3, 'max_features': 3, 'min_samples_leaf': 4, 'min_samples_split': 4, 'splitter': 'best'}\n",
            "Testing parameters 5250 / 30780  :  {'max_depth': 3, 'max_features': 3, 'min_samples_leaf': 13, 'min_samples_split': 17, 'splitter': 'best'}\n",
            "Testing parameters 5600 / 30780  :  {'max_depth': 3, 'max_features': 4, 'min_samples_leaf': 4, 'min_samples_split': 12, 'splitter': 'best'}\n",
            "Testing parameters 5950 / 30780  :  {'max_depth': 3, 'max_features': 4, 'min_samples_leaf': 14, 'min_samples_split': 7, 'splitter': 'best'}\n",
            "Testing parameters 6300 / 30780  :  {'max_depth': 4, 'max_features': 2, 'min_samples_leaf': 5, 'min_samples_split': 2, 'splitter': 'best'}\n",
            "Testing parameters 6650 / 30780  :  {'max_depth': 4, 'max_features': 2, 'min_samples_leaf': 14, 'min_samples_split': 15, 'splitter': 'best'}\n",
            "Testing parameters 7000 / 30780  :  {'max_depth': 4, 'max_features': 3, 'min_samples_leaf': 5, 'min_samples_split': 10, 'splitter': 'best'}\n",
            "Testing parameters 7350 / 30780  :  {'max_depth': 4, 'max_features': 3, 'min_samples_leaf': 15, 'min_samples_split': 5, 'splitter': 'best'}\n",
            "Testing parameters 7700 / 30780  :  {'max_depth': 4, 'max_features': 4, 'min_samples_leaf': 5, 'min_samples_split': 18, 'splitter': 'best'}\n",
            "Testing parameters 8050 / 30780  :  {'max_depth': 4, 'max_features': 4, 'min_samples_leaf': 15, 'min_samples_split': 13, 'splitter': 'best'}\n",
            "Testing parameters 8400 / 30780  :  {'max_depth': 5, 'max_features': 2, 'min_samples_leaf': 6, 'min_samples_split': 8, 'splitter': 'best'}\n",
            "Testing parameters 8750 / 30780  :  {'max_depth': 5, 'max_features': 2, 'min_samples_leaf': 16, 'min_samples_split': 3, 'splitter': 'best'}\n",
            "Testing parameters 9100 / 30780  :  {'max_depth': 5, 'max_features': 3, 'min_samples_leaf': 6, 'min_samples_split': 16, 'splitter': 'best'}\n",
            "Testing parameters 9450 / 30780  :  {'max_depth': 5, 'max_features': 3, 'min_samples_leaf': 16, 'min_samples_split': 11, 'splitter': 'best'}\n",
            "Testing parameters 9800 / 30780  :  {'max_depth': 5, 'max_features': 4, 'min_samples_leaf': 7, 'min_samples_split': 6, 'splitter': 'best'}\n",
            "Testing parameters 10150 / 30780  :  {'max_depth': 5, 'max_features': 4, 'min_samples_leaf': 16, 'min_samples_split': 19, 'splitter': 'best'}\n",
            "Testing parameters 10500 / 30780  :  {'max_depth': 6, 'max_features': 2, 'min_samples_leaf': 7, 'min_samples_split': 14, 'splitter': 'best'}\n",
            "Testing parameters 10850 / 30780  :  {'max_depth': 6, 'max_features': 2, 'min_samples_leaf': 17, 'min_samples_split': 9, 'splitter': 'best'}\n",
            "Testing parameters 11200 / 30780  :  {'max_depth': 6, 'max_features': 3, 'min_samples_leaf': 8, 'min_samples_split': 4, 'splitter': 'best'}\n",
            "Testing parameters 11550 / 30780  :  {'max_depth': 6, 'max_features': 3, 'min_samples_leaf': 17, 'min_samples_split': 17, 'splitter': 'best'}\n",
            "Testing parameters 11900 / 30780  :  {'max_depth': 6, 'max_features': 4, 'min_samples_leaf': 8, 'min_samples_split': 12, 'splitter': 'best'}\n",
            "Testing parameters 12250 / 30780  :  {'max_depth': 6, 'max_features': 4, 'min_samples_leaf': 18, 'min_samples_split': 7, 'splitter': 'best'}\n",
            "Testing parameters 12600 / 30780  :  {'max_depth': 7, 'max_features': 2, 'min_samples_leaf': 9, 'min_samples_split': 2, 'splitter': 'best'}\n",
            "Testing parameters 12950 / 30780  :  {'max_depth': 7, 'max_features': 2, 'min_samples_leaf': 18, 'min_samples_split': 15, 'splitter': 'best'}\n",
            "Testing parameters 13300 / 30780  :  {'max_depth': 7, 'max_features': 3, 'min_samples_leaf': 9, 'min_samples_split': 10, 'splitter': 'best'}\n",
            "Testing parameters 13650 / 30780  :  {'max_depth': 7, 'max_features': 3, 'min_samples_leaf': 19, 'min_samples_split': 5, 'splitter': 'best'}\n",
            "Testing parameters 14000 / 30780  :  {'max_depth': 7, 'max_features': 4, 'min_samples_leaf': 9, 'min_samples_split': 18, 'splitter': 'best'}\n",
            "Testing parameters 14350 / 30780  :  {'max_depth': 7, 'max_features': 4, 'min_samples_leaf': 19, 'min_samples_split': 13, 'splitter': 'best'}\n",
            "Testing parameters 14700 / 30780  :  {'max_depth': 8, 'max_features': 2, 'min_samples_leaf': 10, 'min_samples_split': 8, 'splitter': 'best'}\n",
            "Testing parameters 15050 / 30780  :  {'max_depth': 8, 'max_features': 3, 'min_samples_leaf': 1, 'min_samples_split': 3, 'splitter': 'best'}\n",
            "Testing parameters 15400 / 30780  :  {'max_depth': 8, 'max_features': 3, 'min_samples_leaf': 10, 'min_samples_split': 16, 'splitter': 'best'}\n",
            "Testing parameters 15750 / 30780  :  {'max_depth': 8, 'max_features': 4, 'min_samples_leaf': 1, 'min_samples_split': 11, 'splitter': 'best'}\n",
            "Testing parameters 16100 / 30780  :  {'max_depth': 8, 'max_features': 4, 'min_samples_leaf': 11, 'min_samples_split': 6, 'splitter': 'best'}\n",
            "Testing parameters 16450 / 30780  :  {'max_depth': 9, 'max_features': 2, 'min_samples_leaf': 1, 'min_samples_split': 19, 'splitter': 'best'}\n",
            "Testing parameters 16800 / 30780  :  {'max_depth': 9, 'max_features': 2, 'min_samples_leaf': 11, 'min_samples_split': 14, 'splitter': 'best'}\n",
            "Testing parameters 17150 / 30780  :  {'max_depth': 9, 'max_features': 3, 'min_samples_leaf': 2, 'min_samples_split': 9, 'splitter': 'best'}\n",
            "Testing parameters 17500 / 30780  :  {'max_depth': 9, 'max_features': 3, 'min_samples_leaf': 12, 'min_samples_split': 4, 'splitter': 'best'}\n",
            "Testing parameters 17850 / 30780  :  {'max_depth': 9, 'max_features': 4, 'min_samples_leaf': 2, 'min_samples_split': 17, 'splitter': 'best'}\n",
            "Testing parameters 18200 / 30780  :  {'max_depth': 9, 'max_features': 4, 'min_samples_leaf': 12, 'min_samples_split': 12, 'splitter': 'best'}\n",
            "Testing parameters 18550 / 30780  :  {'max_depth': 10, 'max_features': 2, 'min_samples_leaf': 3, 'min_samples_split': 7, 'splitter': 'best'}\n",
            "Testing parameters 18900 / 30780  :  {'max_depth': 10, 'max_features': 2, 'min_samples_leaf': 13, 'min_samples_split': 2, 'splitter': 'best'}\n",
            "Testing parameters 19250 / 30780  :  {'max_depth': 10, 'max_features': 3, 'min_samples_leaf': 3, 'min_samples_split': 15, 'splitter': 'best'}\n",
            "Testing parameters 19600 / 30780  :  {'max_depth': 10, 'max_features': 3, 'min_samples_leaf': 13, 'min_samples_split': 10, 'splitter': 'best'}\n",
            "Testing parameters 19950 / 30780  :  {'max_depth': 10, 'max_features': 4, 'min_samples_leaf': 4, 'min_samples_split': 5, 'splitter': 'best'}\n",
            "Testing parameters 20300 / 30780  :  {'max_depth': 10, 'max_features': 4, 'min_samples_leaf': 13, 'min_samples_split': 18, 'splitter': 'best'}\n",
            "Testing parameters 20650 / 30780  :  {'max_depth': 11, 'max_features': 2, 'min_samples_leaf': 4, 'min_samples_split': 13, 'splitter': 'best'}\n",
            "Testing parameters 21000 / 30780  :  {'max_depth': 11, 'max_features': 2, 'min_samples_leaf': 14, 'min_samples_split': 8, 'splitter': 'best'}\n",
            "Testing parameters 21350 / 30780  :  {'max_depth': 11, 'max_features': 3, 'min_samples_leaf': 5, 'min_samples_split': 3, 'splitter': 'best'}\n",
            "Testing parameters 21700 / 30780  :  {'max_depth': 11, 'max_features': 3, 'min_samples_leaf': 14, 'min_samples_split': 16, 'splitter': 'best'}\n",
            "Testing parameters 22050 / 30780  :  {'max_depth': 11, 'max_features': 4, 'min_samples_leaf': 5, 'min_samples_split': 11, 'splitter': 'best'}\n",
            "Testing parameters 22400 / 30780  :  {'max_depth': 11, 'max_features': 4, 'min_samples_leaf': 15, 'min_samples_split': 6, 'splitter': 'best'}\n",
            "Testing parameters 22750 / 30780  :  {'max_depth': 12, 'max_features': 2, 'min_samples_leaf': 5, 'min_samples_split': 19, 'splitter': 'best'}\n",
            "Testing parameters 23100 / 30780  :  {'max_depth': 12, 'max_features': 2, 'min_samples_leaf': 15, 'min_samples_split': 14, 'splitter': 'best'}\n",
            "Testing parameters 23450 / 30780  :  {'max_depth': 12, 'max_features': 3, 'min_samples_leaf': 6, 'min_samples_split': 9, 'splitter': 'best'}\n",
            "Testing parameters 23800 / 30780  :  {'max_depth': 12, 'max_features': 3, 'min_samples_leaf': 16, 'min_samples_split': 4, 'splitter': 'best'}\n",
            "Testing parameters 24150 / 30780  :  {'max_depth': 12, 'max_features': 4, 'min_samples_leaf': 6, 'min_samples_split': 17, 'splitter': 'best'}\n",
            "Testing parameters 24500 / 30780  :  {'max_depth': 12, 'max_features': 4, 'min_samples_leaf': 16, 'min_samples_split': 12, 'splitter': 'best'}\n",
            "Testing parameters 24850 / 30780  :  {'max_depth': 13, 'max_features': 2, 'min_samples_leaf': 7, 'min_samples_split': 7, 'splitter': 'best'}\n",
            "Testing parameters 25200 / 30780  :  {'max_depth': 13, 'max_features': 2, 'min_samples_leaf': 17, 'min_samples_split': 2, 'splitter': 'best'}\n",
            "Testing parameters 25550 / 30780  :  {'max_depth': 13, 'max_features': 3, 'min_samples_leaf': 7, 'min_samples_split': 15, 'splitter': 'best'}\n",
            "Testing parameters 25900 / 30780  :  {'max_depth': 13, 'max_features': 3, 'min_samples_leaf': 17, 'min_samples_split': 10, 'splitter': 'best'}\n",
            "Testing parameters 26250 / 30780  :  {'max_depth': 13, 'max_features': 4, 'min_samples_leaf': 8, 'min_samples_split': 5, 'splitter': 'best'}\n",
            "Testing parameters 26600 / 30780  :  {'max_depth': 13, 'max_features': 4, 'min_samples_leaf': 17, 'min_samples_split': 18, 'splitter': 'best'}\n",
            "Testing parameters 26950 / 30780  :  {'max_depth': 14, 'max_features': 2, 'min_samples_leaf': 8, 'min_samples_split': 13, 'splitter': 'best'}\n",
            "Testing parameters 27300 / 30780  :  {'max_depth': 14, 'max_features': 2, 'min_samples_leaf': 18, 'min_samples_split': 8, 'splitter': 'best'}\n",
            "Testing parameters 27650 / 30780  :  {'max_depth': 14, 'max_features': 3, 'min_samples_leaf': 9, 'min_samples_split': 3, 'splitter': 'best'}\n",
            "Testing parameters 28000 / 30780  :  {'max_depth': 14, 'max_features': 3, 'min_samples_leaf': 18, 'min_samples_split': 16, 'splitter': 'best'}\n",
            "Testing parameters 28350 / 30780  :  {'max_depth': 14, 'max_features': 4, 'min_samples_leaf': 9, 'min_samples_split': 11, 'splitter': 'best'}\n",
            "Testing parameters 28700 / 30780  :  {'max_depth': 14, 'max_features': 4, 'min_samples_leaf': 19, 'min_samples_split': 6, 'splitter': 'best'}\n",
            "Testing parameters 29050 / 30780  :  {'max_depth': 15, 'max_features': 2, 'min_samples_leaf': 9, 'min_samples_split': 19, 'splitter': 'best'}\n",
            "Testing parameters 29400 / 30780  :  {'max_depth': 15, 'max_features': 2, 'min_samples_leaf': 19, 'min_samples_split': 14, 'splitter': 'best'}\n",
            "Testing parameters 29750 / 30780  :  {'max_depth': 15, 'max_features': 3, 'min_samples_leaf': 10, 'min_samples_split': 9, 'splitter': 'best'}\n",
            "Testing parameters 30100 / 30780  :  {'max_depth': 15, 'max_features': 4, 'min_samples_leaf': 1, 'min_samples_split': 4, 'splitter': 'best'}\n",
            "Testing parameters 30450 / 30780  :  {'max_depth': 15, 'max_features': 4, 'min_samples_leaf': 10, 'min_samples_split': 17, 'splitter': 'best'}\n",
            "\n",
            "Les meilleurs paramètres sont : \n",
            "\t {'splitter': 'best', 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 3, 'max_depth': None}\n",
            "Accuracy on train =  0.96\n",
            "Accuracy on test =  0.96\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8x4sQoqOch-",
        "colab_type": "text"
      },
      "source": [
        "Nous voyons une très bonne précision et aucun overfitting. Notre modèle est satisfaisant et nous avons possiblement trouvé les meilleurs paramètres pour un DecisionTreeClassifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04a9wM5z9vcJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "finale_clf = DecisionTreeClassifier(criterion='gini',random_state=np.random.RandomState(130),**param_grid[best_param_index])\n",
        "finale_clf = finale_clf.fit(training_data, training_class)\n",
        "finale_clf_train_pred = finale_clf.predict(training_data)\n",
        "finale_clf_test_pred = finale_clf.predict(test_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWMipVAjVGF_",
        "colab_type": "code",
        "outputId": "84a6d54b-53d0-4a87-cb0f-6640167989eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 657
        }
      },
      "source": [
        "display(graphviz.Source(export_graphviz(finale_clf)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<graphviz.files.Source at 0x7ff69430f4a8>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: Tree Pages: 1 -->\n<svg width=\"380pt\" height=\"477pt\"\n viewBox=\"0.00 0.00 380.00 477.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 473)\">\n<title>Tree</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-473 376,-473 376,4 -4,4\"/>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"245.5,-469 120.5,-469 120.5,-401 245.5,-401 245.5,-469\"/>\n<text text-anchor=\"middle\" x=\"183\" y=\"-453.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">X[3] &lt;= 0.8</text>\n<text text-anchor=\"middle\" x=\"183\" y=\"-438.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.553</text>\n<text text-anchor=\"middle\" x=\"183\" y=\"-423.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 50</text>\n<text text-anchor=\"middle\" x=\"183\" y=\"-408.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [25, 22, 3]</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\">\n<title>1</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"174.5,-357.5 57.5,-357.5 57.5,-304.5 174.5,-304.5 174.5,-357.5\"/>\n<text text-anchor=\"middle\" x=\"116\" y=\"-342.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.0</text>\n<text text-anchor=\"middle\" x=\"116\" y=\"-327.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 25</text>\n<text text-anchor=\"middle\" x=\"116\" y=\"-312.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [25, 0, 0]</text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M161.0617,-400.9465C153.8946,-389.8215 145.9227,-377.4473 138.7007,-366.237\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"141.4574,-364.0532 133.0993,-357.5422 135.5728,-367.8442 141.4574,-364.0532\"/>\n<text text-anchor=\"middle\" x=\"127.8123\" y=\"-378.2767\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">True</text>\n</g>\n<!-- 2 -->\n<g id=\"node3\" class=\"node\">\n<title>2</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"309.5,-365 192.5,-365 192.5,-297 309.5,-297 309.5,-365\"/>\n<text text-anchor=\"middle\" x=\"251\" y=\"-349.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">X[3] &lt;= 1.65</text>\n<text text-anchor=\"middle\" x=\"251\" y=\"-334.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.211</text>\n<text text-anchor=\"middle\" x=\"251\" y=\"-319.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 25</text>\n<text text-anchor=\"middle\" x=\"251\" y=\"-304.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 22, 3]</text>\n</g>\n<!-- 0&#45;&gt;2 -->\n<g id=\"edge2\" class=\"edge\">\n<title>0&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M205.2657,-400.9465C210.9602,-392.2373 217.1552,-382.7626 223.0938,-373.6801\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"226.1411,-375.4151 228.6842,-365.13 220.2823,-371.5843 226.1411,-375.4151\"/>\n<text text-anchor=\"middle\" x=\"233.8058\" y=\"-385.8998\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">False</text>\n</g>\n<!-- 3 -->\n<g id=\"node4\" class=\"node\">\n<title>3</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"243.5,-261 126.5,-261 126.5,-193 243.5,-193 243.5,-261\"/>\n<text text-anchor=\"middle\" x=\"185\" y=\"-245.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">X[1] &lt;= 2.45</text>\n<text text-anchor=\"middle\" x=\"185\" y=\"-230.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.087</text>\n<text text-anchor=\"middle\" x=\"185\" y=\"-215.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 22</text>\n<text text-anchor=\"middle\" x=\"185\" y=\"-200.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 21, 1]</text>\n</g>\n<!-- 2&#45;&gt;3 -->\n<g id=\"edge3\" class=\"edge\">\n<title>2&#45;&gt;3</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M229.3891,-296.9465C223.8622,-288.2373 217.8494,-278.7626 212.0854,-269.6801\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"214.9729,-267.6979 206.6594,-261.13 209.0626,-271.4487 214.9729,-267.6979\"/>\n</g>\n<!-- 8 -->\n<g id=\"node9\" class=\"node\">\n<title>8</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"372,-253.5 262,-253.5 262,-200.5 372,-200.5 372,-253.5\"/>\n<text text-anchor=\"middle\" x=\"317\" y=\"-238.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.444</text>\n<text text-anchor=\"middle\" x=\"317\" y=\"-223.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 3</text>\n<text text-anchor=\"middle\" x=\"317\" y=\"-208.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 1, 2]</text>\n</g>\n<!-- 2&#45;&gt;8 -->\n<g id=\"edge8\" class=\"edge\">\n<title>2&#45;&gt;8</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M272.6109,-296.9465C279.671,-285.8215 287.5239,-273.4473 294.6381,-262.237\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"297.7528,-263.8609 300.1559,-253.5422 291.8425,-260.1101 297.7528,-263.8609\"/>\n</g>\n<!-- 4 -->\n<g id=\"node5\" class=\"node\">\n<title>4</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"174,-157 64,-157 64,-89 174,-89 174,-157\"/>\n<text text-anchor=\"middle\" x=\"119\" y=\"-141.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">X[3] &lt;= 1.05</text>\n<text text-anchor=\"middle\" x=\"119\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.375</text>\n<text text-anchor=\"middle\" x=\"119\" y=\"-111.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 4</text>\n<text text-anchor=\"middle\" x=\"119\" y=\"-96.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 3, 1]</text>\n</g>\n<!-- 3&#45;&gt;4 -->\n<g id=\"edge4\" class=\"edge\">\n<title>3&#45;&gt;4</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M163.3891,-192.9465C157.8622,-184.2373 151.8494,-174.7626 146.0854,-165.6801\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"148.9729,-163.6979 140.6594,-157.13 143.0626,-167.4487 148.9729,-163.6979\"/>\n</g>\n<!-- 7 -->\n<g id=\"node8\" class=\"node\">\n<title>7</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"309.5,-149.5 192.5,-149.5 192.5,-96.5 309.5,-96.5 309.5,-149.5\"/>\n<text text-anchor=\"middle\" x=\"251\" y=\"-134.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.0</text>\n<text text-anchor=\"middle\" x=\"251\" y=\"-119.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 18</text>\n<text text-anchor=\"middle\" x=\"251\" y=\"-104.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 18, 0]</text>\n</g>\n<!-- 3&#45;&gt;7 -->\n<g id=\"edge7\" class=\"edge\">\n<title>3&#45;&gt;7</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M206.6109,-192.9465C213.671,-181.8215 221.5239,-169.4473 228.6381,-158.237\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"231.7528,-159.8609 234.1559,-149.5422 225.8425,-156.1101 231.7528,-159.8609\"/>\n</g>\n<!-- 5 -->\n<g id=\"node6\" class=\"node\">\n<title>5</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"110,-53 0,-53 0,0 110,0 110,-53\"/>\n<text text-anchor=\"middle\" x=\"55\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.0</text>\n<text text-anchor=\"middle\" x=\"55\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 2</text>\n<text text-anchor=\"middle\" x=\"55\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 2, 0]</text>\n</g>\n<!-- 4&#45;&gt;5 -->\n<g id=\"edge5\" class=\"edge\">\n<title>4&#45;&gt;5</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M96.436,-88.9777C90.6059,-80.187 84.3169,-70.7044 78.443,-61.8477\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"81.1838,-59.6478 72.7399,-53.2485 75.3502,-63.5167 81.1838,-59.6478\"/>\n</g>\n<!-- 6 -->\n<g id=\"node7\" class=\"node\">\n<title>6</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"238,-53 128,-53 128,0 238,0 238,-53\"/>\n<text text-anchor=\"middle\" x=\"183\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.5</text>\n<text text-anchor=\"middle\" x=\"183\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 2</text>\n<text text-anchor=\"middle\" x=\"183\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 1, 1]</text>\n</g>\n<!-- 4&#45;&gt;6 -->\n<g id=\"edge6\" class=\"edge\">\n<title>4&#45;&gt;6</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M141.564,-88.9777C147.3941,-80.187 153.6831,-70.7044 159.557,-61.8477\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"162.6498,-63.5167 165.2601,-53.2485 156.8162,-59.6478 162.6498,-63.5167\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iUe_Wue-dYb",
        "colab_type": "text"
      },
      "source": [
        "# III - Naive Bayes Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6VaHuLN_Bfr",
        "colab_type": "text"
      },
      "source": [
        "Le but de cette partie sera de maîtriser la K-fold cross-validation de manière programmatique. Contrairement à ce que nous avons fait dans les parties précédentes, nous allons donc ici programmer nos propres fonctions dans ce but."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjLv_ihMANj0",
        "colab_type": "text"
      },
      "source": [
        "La première chose à faire est de récupérer chaque ligne de texte comme une observation. Les quatres catégories target correspondent au fichier d'origine du texte. Il s'agit des quatre fichiers dans le dossier NaiveBayesData."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uo6kCDUn_XVC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fruit_text_path = my_path+\"TextTP/NaiveBayesData/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oi8TqyScAyRS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_files = [\"apple_the_company\", \"apple_the_fruit\", \"banana\", \"microsoft\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0rMnMG6BD6K",
        "colab_type": "text"
      },
      "source": [
        "pour faire le plus simple possible, nous aurons deux listes, un e liste avec, dans l'ordre, les textes (un texte correspond à une ligne des fichiers texte) et, dans l'autre, la catégorie auxquelles appartiennent nos textes. L'ordre est ainsi maintenu et le lien entre les deux sera fait grâce aux index ; ainsi, le texte à l'index n du fichier texts a la catégorie indiquée (poar un numéro 0 à 3) à l'index n du fichier categories)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4K_9OiTeBDZt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_texts=[]\n",
        "data_categories = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uphYfZZqCBHS",
        "colab_type": "text"
      },
      "source": [
        "Nous pouvons lire dans des fichiers texte grâce à des fonctions inclues dans Python."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nY-r1_ECH3L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for filename in text_files:\n",
        "    with open(fruit_text_path+filename+\".txt\",\"r\") as file:\n",
        "        lines = file.read().splitlines()\n",
        "        # Ajoute tous les textes sous forme de liste.\n",
        "        data_texts.extend(lines)\n",
        "        # La ligne suivante ajoute autant de fois la category \n",
        "        # qu'il y a de texte dans le fichier.\n",
        "        data_categories.extend([text_files.index(filename)]*len(lines))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1wcIpK-Evbk",
        "colab_type": "text"
      },
      "source": [
        "Les données brutes sont prêtes.\n",
        "\n",
        "Dans le cadre de cet exercice, nous manipulerons un simple modèle appelé Naive Bayes Classifier. Comme d'habitude, nous devons l'importer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WU5WZcnw-hQi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WaONjek2FKrG",
        "colab_type": "text"
      },
      "source": [
        "Comme nous l'avons fait dans la première partie, nous allons transformer les texts grâce à notre CountVectorizer (nous avons toujours l'instance de celui-ci en mémoire). Nous allons également directement transformer les vecteurs obtenus en array."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8hdS-Sl_SGC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vect_data_texts = count_vect.fit_transform(data_texts).toarray()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dPZHraaF7Ez",
        "colab_type": "text"
      },
      "source": [
        "Comme nous le voyons grâce aux informations de leur taille, nos vecteurs et nos réponses ont la même taille : 200."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3VL9WLXFlnA",
        "colab_type": "code",
        "outputId": "f0cef246-f95e-4e57-d086-ce2578898dfb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(vect_data_texts.shape)\n",
        "print(len(data_categories))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(200, 3223)\n",
            "200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_36EaQ6GK6U",
        "colab_type": "text"
      },
      "source": [
        "Il s'agit désormais de préparer nos données en plusieurs échantillons pour la k-fold cross-validation. Nous allons programmer une fonction pour cela, que nous allons tâcher de rendre adaptable à un nombre de fold quelconque (mais 5 par défaut)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pi8O40WkF5JR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from random import shuffle\n",
        "\n",
        "def get_index_folds(data, n_fold=5):\n",
        "    taille = len(data)\n",
        "    if n_fold>taille:\n",
        "        raise ValueError(\"You can't fold %i times : data is length %i\"%(n_fold, taille))\n",
        "    fold_indices = []\n",
        "    # On mélange la liste d'index.\n",
        "    shuffled_indices = list(range(taille))\n",
        "    shuffle(shuffled_indices)\n",
        "    for i in range(n_fold):\n",
        "        fold_indices.append((\n",
        "            shuffled_indices[0:i*(taille//n_fold)]+shuffled_indices[(i+1)*(taille//n_fold):],\n",
        "            shuffled_indices[i*(taille//n_fold):(i+1)*(taille//n_fold)]\n",
        "            ))\n",
        "    return fold_indices"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9IEzFJ4JPUO",
        "colab_type": "text"
      },
      "source": [
        "La fonction get_index_folds renvoies n tuples : chaque tuple a pour premier élément un liste d'indice \"train\" et une liste d'indices \"test\", sachant que chaque indice apparait au total une fois dans chaque tuple."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ah96QNUFJmKS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "folds = get_index_folds(data_texts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AsEmUqHyGIqo",
        "colab_type": "text"
      },
      "source": [
        "Instancions simplement notre modèle."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKPEkauDFqQq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnb = MultinomialNB()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CP9oZStLNsv",
        "colab_type": "text"
      },
      "source": [
        "Nous pouvons maintenant entrâiner notre modèle en suivant un k_fold cross-validation, grâce aux folds préparés."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWEskdyALVRe",
        "colab_type": "code",
        "outputId": "681a5445-9ac4-4258-a4bd-429b31741675",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        }
      },
      "source": [
        "train_results=[]\n",
        "test_results=[]\n",
        "for fold in folds:\n",
        "    mnb = mnb.fit([vect_data_texts[i] for i in fold[0]],\n",
        "                  [data_categories[i] for i in fold[0]])\n",
        "    mnb_train = mnb.predict([vect_data_texts[i] for i in fold[0]])\n",
        "    mnb_pred = mnb.predict([vect_data_texts[i] for i in fold[1]])\n",
        "    train_result = accuracy_score([data_categories[i] for i in fold[0]], mnb_train)\n",
        "    test_result = accuracy_score([data_categories[i] for i in fold[1]], mnb_pred)\n",
        "    print(\"Précision sur train :\", train_result)\n",
        "    print(\"Précision sur test :\", test_result)\n",
        "    train_results.append(train_result)\n",
        "    test_results.append(test_result)\n",
        "print(\"\\nMoyenne sur le train :\", np.mean(train_results))\n",
        "print(\"Moyenne sur le test :\", np.mean(test_results))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Précision sur train : 1.0\n",
            "Précision sur test : 0.975\n",
            "Précision sur train : 1.0\n",
            "Précision sur test : 0.95\n",
            "Précision sur train : 1.0\n",
            "Précision sur test : 1.0\n",
            "Précision sur train : 1.0\n",
            "Précision sur test : 1.0\n",
            "Précision sur train : 1.0\n",
            "Précision sur test : 0.975\n",
            "\n",
            "Moyenne sur le train : 1.0\n",
            "Moyenne sur le test : 0.9799999999999999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lf39UrTiW34y",
        "colab_type": "text"
      },
      "source": [
        "Vu les scores obtenus, cela prédit très bien sans démontrer d'overfitting."
      ]
    }
  ]
}